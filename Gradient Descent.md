# Gradient Descent

#### 核心思想：

使用梯度下降算法，寻找似的代价函数收敛于最低点的参数值，使得假设函数最优拟合训练集

#### 相关概念：

梯度下降算法，可以用来最小化线性回归问题中的代价函数和其他函数等更一般的问题

convergence 收敛

simultaneous update 同步更新

导数与偏导数

- 一元函数中，导数标明了函数的变化率、斜率；
- 多元函数中，函数关于其中一个变量的导数而保持其他变量恒定就是偏导数，这里梯度下降同步更新用的就是偏导数，表示固定面上一点的切线斜率，偏导数f'x(x0,y0)表示固定面上一点对x轴的切线斜率；偏导数f'y(x0,y0)表示固定面上一点对y轴的切线斜率、

#### 梯度下降算法的分类：

- Batch（每一步都用到训练集）
- 其他（只用到训练集中的一些子集）

